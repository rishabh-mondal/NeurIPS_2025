{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db24bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from supervision.metrics import MeanAveragePrecision\n",
    "from rfdetr import RFDETRBase, RFDETRLarge\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Set GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to CSV\n",
    "result_df_path = \"sentinel_results.csv\"\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = \"runs/sentinel_data/checkpoint0029.pth\"\n",
    "\n",
    "# Name of the experiment\n",
    "experiment = \"Sentinel Train to Sentinel Test\"\n",
    "\n",
    "# Dataset dir\n",
    "dataset_dir = \"data/sentinel_data\"\n",
    "\n",
    "# Model\n",
    "model_name = \"RFDETRLarge Epoch 30\"\n",
    "\n",
    "\n",
    "# separate the source and target states from the experiment name\n",
    "train_region, test_region = experiment.split(\" to \")\n",
    "print(f\"Train region: {train_region}, Test region: {test_region}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02959e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_dataset = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=f\"{dataset_dir}/test\",\n",
    "    annotations_path=f\"{dataset_dir}/test/_annotations.coco.json\",\n",
    ")\n",
    "print(f\"Loaded Dataset: {len(sv_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RFDETRBase(pretrain_weights=checkpoint)\n",
    "model = RFDETRLarge(pretrain_weights=checkpoint)\n",
    "\n",
    "targets = []\n",
    "predictions = []\n",
    "\n",
    "for path, image, annotations in tqdm(sv_dataset):\n",
    "    image = Image.open(path)\n",
    "    detections = model.predict(image, threshold=0.5)\n",
    "\n",
    "    targets.append(annotations)\n",
    "    predictions.append(detections)\n",
    "\n",
    "\n",
    "print(len(targets), len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c60f1b",
   "metadata": {},
   "source": [
    "## mAP Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085bd677",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mAP calculation (non-class agnostic)\n",
    "print (100 * \"=\")\n",
    "print(\"Class-specific mAP\")\n",
    "print (100 * \"=\")\n",
    "map_metric = MeanAveragePrecision(class_agnostic=False)\n",
    "map_result = map_metric.update(predictions, targets).compute()\n",
    "# map_result.plot()\n",
    "\n",
    "matched_classes=map_result.matched_classes.tolist()\n",
    "print(f\"Matched classes: {matched_classes}\")\n",
    "\n",
    "# Extract mAP values\n",
    "mAP_50_95 = map_result.map50_95  # mAP 50:95\n",
    "mAP_50 = map_result.map50  # mAP 50\n",
    "mAP_75 = map_result.map75  # mAP 75\n",
    "print(f\"mAP 50:95: {mAP_50_95}, mAP 50: {mAP_50}, mAP 75: {mAP_75}\")\n",
    "\n",
    "# Extract class-wise mAP values\n",
    "num_classes=3\n",
    "final_class_wise_mAP = [0]*num_classes\n",
    "class_wise_mAP=map_result.ap_per_class[:,0].tolist()\n",
    "for cls, mAP in zip(matched_classes, class_wise_mAP):\n",
    "    print(f\"cls: {cls}, mAP: {mAP}\")\n",
    "    final_class_wise_mAP[cls] = mAP\n",
    "\n",
    "# Compute class-agnostic mAP\n",
    "print (100 * \"=\")\n",
    "print(\"Class-agnostic mAP\")\n",
    "print (100 * \"=\")\n",
    "mAP_metric_agnostic = MeanAveragePrecision(class_agnostic=True)\n",
    "mAP_result_agnostic = mAP_metric_agnostic.update(predictions, targets).compute()\n",
    "# Extract class-agnostic mAP values\n",
    "mAP_50_95_agnostic = mAP_result_agnostic.map50_95  # mAP 50:95\n",
    "mAP_50_agnostic = mAP_result_agnostic.map50  # mAP 50\n",
    "mAP_75_agnostic = mAP_result_agnostic.map75  # mAP 75\n",
    "print(f\"CA mAP 50:95: {mAP_50_95_agnostic}, CA mAP 50: {mAP_50_agnostic}, CA mAP 75: {mAP_75_agnostic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed82acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"Model\",\"Train\", \"Test\", \"Images\", \"CFCBK\", \"FCBK\", \"Zigzag\", \"Class-agnostic AP\"]\n",
    "result_df = pd.DataFrame(columns=columns)\n",
    "# new_row = [experiment] + final_class_wise_mAP + [mAP_50_agnostic]\n",
    "new_row = [model_name, train_region, test_region, len(sv_dataset)] + final_class_wise_mAP + [mAP_50_agnostic]\n",
    "    \n",
    "result_df.loc[len(result_df)] = new_row  # Using loc to add the row\n",
    "\n",
    "# Display DataFrame\n",
    "display(result_df.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.to_csv(result_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame    \n",
    "result=pd.read_csv(result_df_path)\n",
    "result=result.reset_index(drop=True)\n",
    "result = pd.concat([result, result_df], ignore_index=True)\n",
    "display(result.style.hide(axis=\"index\"))\n",
    "result.to_csv(result_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.read_csv(result_df_path)\n",
    "display(result.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result=pd.read_csv(result_df_path)\n",
    "# result = result.iloc[:, [1, 2, -1]]\n",
    "# display(result.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a50ea0",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12737fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = sv.ConfusionMatrix.from_detections(\n",
    "    predictions=predictions,\n",
    "    targets=targets,\n",
    "    classes=sv_dataset.classes,\n",
    ")\n",
    "\n",
    "confusion_matrix.plot(\n",
    "    fig_size=(8,8),\n",
    "    title=f\"Confusion Matrix for {experiment}\",\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c17bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
